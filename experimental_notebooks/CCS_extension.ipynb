{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The autoreload extension is already loaded. To reload it, use:\n",
      "  %reload_ext autoreload\n"
     ]
    }
   ],
   "source": [
    "%load_ext autoreload\n",
    "%autoreload 2\n",
    "import utils\n",
    "import torch\n",
    "import numpy as np\n",
    "import all_classes\n",
    "from tqdm import tqdm\n",
    "from datasets import load_dataset\n",
    "from transformers import AutoTokenizer, AutoModelForSeq2SeqLM, AutoModelForMaskedLM, AutoModelForCausalLM, AutoModel\n",
    "from sklearn.linear_model import LogisticRegression"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "#load datasets\n",
    "dataset_name = \"imdb\"\n",
    "# dataset_name = \"amazon_polarity\"\n",
    "data = load_dataset(\"imdb\")[\"test\"]\n",
    "# data = load_dataset(\"amazon_polarity\")[\"test\"]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Here are a few different model options you can play around with:\n",
    "model_name = \"llama3.2\"\n",
    "# model_name = \"llama3.3\"\n",
    "\n",
    "# the number of hidden dimensions of the model\n",
    "hidden_size = 2048\n",
    "\n",
    "cache_dir = None\n",
    "\n",
    "if model_name == \"llama3.2\":\n",
    "    model_type = \"decoder\"\n",
    "    tokenizer = AutoTokenizer.from_pretrained(\"meta-llama/Llama-3.2-1B-Instruct\", cache_dir=cache_dir, token=True)\n",
    "    model = AutoModel.from_pretrained(\"meta-llama/Llama-3.2-1B-Instruct\", cache_dir=cache_dir, token=True)\n",
    "    hidden_size = model.config.hidden_size\n",
    "else:\n",
    "    print(\"Not implemented!\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'utils' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[1], line 5\u001b[0m\n\u001b[1;32m      3\u001b[0m test_event \u001b[38;5;241m=\u001b[39m \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mIs the sky blue? Answer: Yes\u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[1;32m      4\u001b[0m test_event_c \u001b[38;5;241m=\u001b[39m \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mIs the sky blue? Answer: No\u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[0;32m----> 5\u001b[0m phi_all \u001b[38;5;241m=\u001b[39m \u001b[43mutils\u001b[49m\u001b[38;5;241m.\u001b[39mget_decoder_hidden_states_all(model, tokenizer, test_event, num_layer \u001b[38;5;241m=\u001b[39m \u001b[38;5;241m16\u001b[39m)\n",
      "\u001b[0;31mNameError\u001b[0m: name 'utils' is not defined"
     ]
    }
   ],
   "source": [
    "# Just some code to test out the architecture of llama 3.2\n",
    "# run it if you want to play around with the architecture \n",
    "test_event = \"Is the sky blue? Answer: Yes\"\n",
    "test_event_c = \"Is the sky blue? Answer: No\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 100/100 [01:53<00:00,  1.13s/it]\n"
     ]
    }
   ],
   "source": [
    "neg_hs, pos_hs, y = utils.get_hidden_states_many_examples(model, tokenizer, data, dataset_name, model_type)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[1 1 1 1 1 1 0 1 1 1 1 0 0 1 1 1 0 0 0 0 0 0 0 1 0 0 0 1 1 1 1 0 0 0 1 0 1\n",
      " 0 1 0 0 1 0 0 1 0 0 0 1 1 1 0 1 0 0 0 0 0 0 1 0 1 1 1 1 1 0 0 1 0 0 1 1 1\n",
      " 0 1 0 1 1 1 0 0 0 0 0 0 1 0 1 1 1 0 0 0 1 0 1 0 1 0]\n",
      "(100, 2048)\n",
      "(100, 2048)\n"
     ]
    }
   ],
   "source": [
    "print(y)\n",
    "print(np.shape(neg_hs))\n",
    "print(np.shape(pos_hs))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "\n",
    "## Let's verify that the model's representations are good\n",
    "\n",
    "Before trying CCS, let's make sure there exists a direction that classifies examples as true vs false with high accuracy; if logistic regression accuracy is bad, there's no hope of CCS doing well."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Logistic regression accuracy: 0.92\n"
     ]
    }
   ],
   "source": [
    "\n",
    "# let's create a simple 50/50 train split (the data is already randomized)\n",
    "n = len(y)\n",
    "neg_hs_train, neg_hs_test = neg_hs[:n//2], neg_hs[n//2:]\n",
    "pos_hs_train, pos_hs_test = pos_hs[:n//2], pos_hs[n//2:]\n",
    "y_train, y_test = y[:n//2], y[n//2:]\n",
    "\n",
    "# for simplicity we can just take the difference between positive and negative hidden states\n",
    "# (concatenating also works fine)\n",
    "x_train = neg_hs_train - pos_hs_train\n",
    "x_test = neg_hs_test - pos_hs_test\n",
    "\n",
    "lr = LogisticRegression(class_weight=\"balanced\")\n",
    "lr.fit(x_train, y_train)\n",
    "print(\"Logistic regression accuracy: {}\".format(lr.score(x_test, y_test)))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Testing CCS using different extensions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "CCS accuracy: 0.86\n"
     ]
    }
   ],
   "source": [
    "# Train CCS without any labels and average multiple truth vectors from the last layer\n",
    "ccs = all_classes.CCS(neg_hs_train, pos_hs_train, num_vec = 6)\n",
    "ccs.repeated_train()\n",
    "\n",
    "# Evaluate\n",
    "ccs_acc = ccs.get_acc(neg_hs_test, pos_hs_test, y_test)\n",
    "print(\"CCS accuracy: {}\".format(ccs_acc))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Train CCS and average truth vectors from multiple intermediate layers"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
