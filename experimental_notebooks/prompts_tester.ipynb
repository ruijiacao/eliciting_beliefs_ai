{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...\n",
      "To disable this warning, you can either:\n",
      "\t- Avoid using `tokenizers` before the fork if possible\n",
      "\t- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)\n",
      "Downloading shards: 100%|██████████| 2/2 [02:49<00:00, 84.62s/it] \n",
      "Loading checkpoint shards: 100%|██████████| 2/2 [00:14<00:00,  7.29s/it]\n",
      "Some parameters are on the meta device because they were offloaded to the disk.\n",
      "Device set to use mps\n"
     ]
    }
   ],
   "source": [
    "import torch\n",
    "import utils\n",
    "from transformers import pipeline\n",
    "\n",
    "# model_id = \"meta-llama/Llama-3.2-1B\"\n",
    "\n",
    "model_id = \"meta-llama/Llama-3.2-3B\"\n",
    "\n",
    "pipe = pipeline(\n",
    "    \"text-generation\", \n",
    "    model=model_id, \n",
    "    torch_dtype=torch.bfloat16, \n",
    "    device_map=\"auto\"\n",
    ")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Setting `pad_token_id` to `eos_token_id`:128001 for open-end generation.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Is the Fermat's Last Theorem true or false? Answer: True!\n",
      "The famous French mathematician Pierre de Fermat (1601-1665) claimed to\n"
     ]
    }
   ],
   "source": [
    "#\n",
    "def get_response(test):\n",
    "    response = pipe(test)[0]['generated_text']\n",
    "    return response\n",
    "\n",
    "test = \"Consider the following passage with the associated statement.\\n***Beginning of passage***\\nLast week I talked with some of my students about what they wanted to do after they graduated, and what kind of job prospects they thought they had. Given that I teach students who are training to be doctors, I was surprised do find that most thought that they would not be able to get the jobs they wanted without \\\"outside help\\\". \\\"What kind of help is that?\\\" I asked, expecting them to tell me that they would need a or family friend to help them out. \\\"Surgery ,\\\" one replied. I was pretty alarmed by that response. It seems that the graduates of today are increasingly willing to go under the knife to get ahead of others when it comes to getting a job . One girl told me that she was considering surgery to increase her height. \\\"They break your legs, put in special extending screws, and slowly expand the gap between the two ends of the bone as it re-grows, you can get at least 5 cm taller!\\\" At that point, I was shocked. I am short, I can't deny that, but I don't think I would put myself through months of agony just to be a few centimetres taller. I don't even bother to wear shoes with thick soles, as I'm not trying to hide the fact that I am just not tall! It seems to me that there is a trend towards wanting \\\"perfection\\\" , and that is an ideal that just does not exist in reality. No one is born perfect, yet magazines, TV shows and movies present images of thin, tall, beautiful people as being the norm. Advertisements for slimming aids, beauty treatments and cosmetic surgery clinics fill the pages of newspapers, further creating an idea that \\\"perfection\\\" is a requirement, and that it must be purchased, no matter what the cost. In my opinion, skills, rather than appearance, should determine how successful a person is in his/her chosen career.\\n***End of Passage***\\nWe can know from the passage that the author works as a cat. Is the previous statement true or false? Answer:\"\n",
    "\n",
    "test_2 = \"Is the Fermat's Last Theorem true or false? Answer:\"\n",
    "test_3 = \"Is the  true or false? Answer:\"\n",
    "print(get_response(test_2))"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
